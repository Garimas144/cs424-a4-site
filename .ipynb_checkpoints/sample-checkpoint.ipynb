{
 "cells": [
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-12-01T03:52:22.079820Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 04_build_embeddings.ipynb  (or a .py script)\n",
    "#\n",
    "# Goal:\n",
    "# - Build numeric embeddings for CPS schools using your processed tables\n",
    "# - Project them to 2D using PCA\n",
    "# - Save:\n",
    "#     data/processed/embeddings_cps.csv\n",
    "#     data/processed/embeddings_cps_2d.csv\n",
    "#\n",
    "# Requirements:\n",
    "#   pip install numpy pandas scikit-learn\n",
    "\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Paths and input tables\n",
    "# -------------------------------------------------------------------\n",
    "ROOT = pathlib.Path(\".\")\n",
    "PROC = ROOT / \"data\" / \"processed\"\n",
    "PROC.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "q1_path = PROC / \"cps_q1.csv\"   # safety / attendance / misconduct\n",
    "q2_path = PROC / \"cps_q2.csv\"   # instruction / teachers / leaders / ISAT metrics\n",
    "\n",
    "assert q1_path.exists(), f\"Missing {q1_path} — run 01_prepare.ipynb first.\"\n",
    "assert q2_path.exists(), f\"Missing {q2_path} — run 01_prepare.ipynb first.\"\n",
    "\n",
    "q1 = pd.read_csv(q1_path)\n",
    "q2 = pd.read_csv(q2_path)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Step 1: Standardize column names (same style as A3)\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "# q1: has safety, attendance, misconduct, level, school\n",
    "q1_clean = (\n",
    "    q1.rename(columns={\n",
    "        'Name of School': 'school',\n",
    "        'Elementary, Middle, or High School': 'level',\n",
    "        'Safety Score': 'safety',\n",
    "        'Average Student Attendance': 'attendance',\n",
    "        'Rate of Misconducts (per 100 students)': 'misconduct'\n",
    "    })\n",
    "    .assign(\n",
    "        safety=lambda d: pd.to_numeric(d['safety'], errors='coerce'),\n",
    "        attendance=lambda d: pd.to_numeric(d['attendance'], errors='coerce'),\n",
    "        misconduct=lambda d: pd.to_numeric(d['misconduct'], errors='coerce'),\n",
    "        level=lambda d: d['level'].astype(str),\n",
    "        school=lambda d: d['school'].astype(str)\n",
    "    )\n",
    ")\n",
    "\n",
    "# q2: has instruction, teachers, leaders, ISAT metrics\n",
    "q2_clean = (\n",
    "    q2.rename(columns={\n",
    "        'Name of School': 'school',\n",
    "        'Elementary, Middle, or High School': 'level',\n",
    "        'Instruction Score': 'instr',\n",
    "        'Teachers Score': 'teachers',\n",
    "        'Leaders Score': 'leaders',\n",
    "        'ISAT Exceeding Math %': 'isat_exc_math',\n",
    "        'ISAT Exceeding Reading %': 'isat_exc_read',\n",
    "        'ISAT Value Add Math': 'isat_va_math',\n",
    "        'ISAT Value Add Read': 'isat_va_read'\n",
    "    })\n",
    "    .assign(\n",
    "        instr=lambda d: pd.to_numeric(d['instr'], errors='coerce'),\n",
    "        teachers=lambda d: pd.to_numeric(d['teachers'], errors='coerce'),\n",
    "        leaders=lambda d: pd.to_numeric(d['leaders'], errors='coerce'),\n",
    "        isat_exc_math=lambda d: pd.to_numeric(d['isat_exc_math'], errors='coerce'),\n",
    "        isat_exc_read=lambda d: pd.to_numeric(d['isat_exc_read'], errors='coerce'),\n",
    "        isat_va_math=lambda d: pd.to_numeric(d['isat_va_math'], errors='coerce'),\n",
    "        isat_va_read=lambda d: pd.to_numeric(d['isat_va_read'], errors='coerce'),\n",
    "        level=lambda d: d['level'].astype(str),\n",
    "        school=lambda d: d['school'].astype(str)\n",
    "    )\n",
    ")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Step 2: Merge into a single table for embeddings\n",
    "#   - Use q2_clean as \"base\" (because it already has all support × ISAT metrics)\n",
    "#   - Left-join safety / attendance / misconduct from q1_clean by school\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "base = q2_clean.copy()\n",
    "\n",
    "# Only keep the columns from q1 we need for the merge\n",
    "q1_subset = q1_clean[['school', 'safety', 'attendance', 'misconduct']].drop_duplicates('school')\n",
    "\n",
    "df = base.merge(q1_subset, on='school', how='left', suffixes=('', '_from_q1'))\n",
    "\n",
    "# Ensure level is present and cleaned\n",
    "if 'level_x' in df.columns and 'level_y' in df.columns:\n",
    "    # If both exist, prefer the one from q2_clean\n",
    "    df['level'] = df['level_x'].fillna(df['level_y'])\n",
    "    df = df.drop(columns=['level_x', 'level_y'])\n",
    "elif 'level_x' in df.columns:\n",
    "    df = df.rename(columns={'level_x': 'level'})\n",
    "elif 'level' not in df.columns:\n",
    "    df['level'] = \"Unknown\"\n",
    "\n",
    "df['level'] = df['level'].astype(str)\n",
    "df['school'] = df['school'].astype(str)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Step 3: Choose numeric features for the embedding\n",
    "#   These are the dimensions of your embedding vector.\n",
    "#\n",
    "#   Intuition:\n",
    "#   - safety / attendance / misconduct capture climate & behavior\n",
    "#   - instr / teachers / leaders capture support & staffing quality\n",
    "#   - ISAT metrics capture academic performance and value add\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "feature_cols = [\n",
    "    'safety',\n",
    "    'attendance',\n",
    "    'misconduct',\n",
    "    'instr',\n",
    "    'teachers',\n",
    "    'leaders',\n",
    "    'isat_exc_math',\n",
    "    'isat_exc_read',\n",
    "    'isat_va_math',\n",
    "    'isat_va_read'\n",
    "]\n",
    "\n",
    "# Keep only rows that have at least SOME data across these features\n",
    "df_features = df[['school', 'level'] + feature_cols].copy()\n",
    "\n",
    "# At least one non-null feature\n",
    "mask_has_any = df_features[feature_cols].notnull().any(axis=1)\n",
    "df_features = df_features[mask_has_any].reset_index(drop=True)\n",
    "\n",
    "print(\"Number of schools in embedding:\", len(df_features))\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Step 4: Impute missing values and normalize\n",
    "#\n",
    "#  - Imputation: replace missing entries with median of that column\n",
    "#  - Scaling: StandardScaler -> each feature ~ N(0, 1)\n",
    "#\n",
    "#  The *scaled, imputed* vectors are the actual embeddings.\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "X_raw = df_features[feature_cols].values\n",
    "\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "X_imputed = imputer.fit_transform(X_raw)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_imputed)\n",
    "\n",
    "print(\"Embedding matrix shape:\", X_scaled.shape)  # (n_schools, n_features)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Step 5: Save full embeddings (high-dimensional space)\n",
    "#\n",
    "#  embeddings_cps.csv will contain:\n",
    "#   - id: integer ID for linking\n",
    "#   - school, level\n",
    "#   - original numeric features\n",
    "#   - feat_1 ... feat_K: standardized embedding coordinates ⟂\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "n_samples, n_dims = X_scaled.shape\n",
    "embed_col_names = [f\"feat_{i+1}\" for i in range(n_dims)]\n",
    "\n",
    "embeddings_df = pd.DataFrame(X_scaled, columns=embed_col_names)\n",
    "embeddings_df.insert(0, \"id\", np.arange(n_samples))            # unique numeric ID\n",
    "embeddings_df.insert(1, \"school\", df_features[\"school\"].values)\n",
    "embeddings_df.insert(2, \"level\", df_features[\"level\"].values)\n",
    "\n",
    "# Also store the original numeric values for tooltips / explanations\n",
    "for col in feature_cols:\n",
    "    embeddings_df[col] = df_features[col].values\n",
    "\n",
    "embeddings_out = PROC / \"embeddings_cps.csv\"\n",
    "embeddings_df.to_csv(embeddings_out, index=False)\n",
    "print(\"Wrote high-dimensional embeddings to:\", embeddings_out)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Step 6: 2D projection with PCA\n",
    "#\n",
    "#  - Take the standardized embedding (X_scaled)\n",
    "#  - Run PCA with 2 components\n",
    "#  - Store the result as x, y for your main scatterplot.\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "pca = PCA(n_components=2, random_state=0)\n",
    "X_2d = pca.fit_transform(X_scaled)\n",
    "\n",
    "proj_df = pd.DataFrame({\n",
    "    \"id\": embeddings_df[\"id\"],\n",
    "    \"school\": embeddings_df[\"school\"],\n",
    "    \"level\": embeddings_df[\"level\"],\n",
    "    \"x\": X_2d[:, 0],\n",
    "    \"y\": X_2d[:, 1],\n",
    "})\n",
    "\n",
    "# Optionally copy a few metrics for convenient coloring/tooltip in Vega-Lite\n",
    "for col in [\"safety\", \"attendance\", \"misconduct\", \"instr\", \"teachers\", \"leaders\"]:\n",
    "    if col in embeddings_df.columns:\n",
    "        proj_df[col] = embeddings_df[col]\n",
    "\n",
    "emb_2d_out = PROC / \"embeddings_cps_2d.csv\"\n",
    "proj_df.to_csv(emb_2d_out, index=False)\n",
    "print(\"Wrote 2D projection to:\", emb_2d_out)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# (Optional) If you later want a non-linear layout like UMAP:\n",
    "#\n",
    "#   pip install umap-learn\n",
    "#   from umap import UMAP\n",
    "#   umap = UMAP(n_components=2, random_state=0)\n",
    "#   X_umap = umap.fit_transform(X_scaled)\n",
    "#   ... then save x_umap, y_umap similarly.\n",
    "# -------------------------------------------------------------------\n",
    "\n"
   ],
   "id": "fbc121e30a2defb3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "72ee670c82f8a15f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
