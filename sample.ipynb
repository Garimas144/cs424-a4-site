{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T23:38:20.801833Z",
     "start_time": "2025-12-09T23:38:20.616260Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pathlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# =================================================================\n",
    "# CONFIGURATION\n",
    "# =================================================================\n",
    "ROOT = pathlib.Path(\".\")\n",
    "DATA = ROOT / \"data\"\n",
    "PROC = DATA / \"processed\"\n",
    "PROC.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"COMPLETE EMBEDDING PIPELINE - TASK 1.1 & 1.2\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# =================================================================\n",
    "# LOAD DATA\n",
    "# =================================================================\n",
    "print(\"\\n[1/8] Loading raw data...\")\n",
    "\n",
    "raw_path = DATA / \"CPS_Data.csv\"\n",
    "assert raw_path.exists(), f\"Expected raw file at {raw_path}\"\n",
    "\n",
    "df = pd.read_csv(raw_path)\n",
    "print(f\"‚úì Loaded: {raw_path.name}\")\n",
    "print(f\"  Rows: {len(df)}, Columns: {len(df.columns)}\")\n",
    "\n",
    "\n",
    "# CLEAN PERCENTAGE-LIKE STRINGS (e.g., \"96.0%\") -------------------\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == object:\n",
    "        # If more than half the non-null values end with '%', treat as percentage\n",
    "        sample = df[col].dropna().astype(str)\n",
    "        if len(sample) == 0:\n",
    "            continue\n",
    "        frac_percent = (sample.str.strip().str.endswith('%')).mean()\n",
    "        if frac_percent > 0.5:\n",
    "            # Remove '%' and convert to float\n",
    "            df[col] = (\n",
    "                df[col]\n",
    "                .astype(str)\n",
    "                .str.strip()\n",
    "                .str.replace('%', '', regex=False)\n",
    "            )\n",
    "\n",
    "# =================================================================\n",
    "# TASK 1.1: CONSTRUCT EMBEDDINGS\n",
    "# =================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TASK 1.1: CONSTRUCTING EMBEDDINGS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Find school ID column\n",
    "school_col = None\n",
    "for col in ['School ID', 'school', 'name', 'id']:\n",
    "    if col in df.columns:\n",
    "        school_col = col\n",
    "        break\n",
    "\n",
    "if not school_col:\n",
    "    raise ValueError(\"No school ID column found\")\n",
    "\n",
    "# Standardize school ID to string\n",
    "df['school'] = df[school_col].astype(str)\n",
    "print(f\"\\n[2/8] School identifier: '{school_col}' ‚Üí 'school'\")\n",
    "\n",
    "# Find and map level column\n",
    "level_col = None\n",
    "for col in ['Elementary, Middle, or High School', 'level', 'type']:\n",
    "    if col in df.columns:\n",
    "        level_col = col\n",
    "        break\n",
    "\n",
    "if level_col:\n",
    "    # Map to ES/MS/HS\n",
    "    df['level'] = df[level_col].astype(str).apply(lambda x:\n",
    "        'ES' if 'elem' in x.lower() or x.lower() == 'es' else\n",
    "        'MS' if 'middle' in x.lower() or x.lower() == 'ms' else\n",
    "        'HS' if 'high' in x.lower() or x.lower() == 'hs' else x\n",
    "    )\n",
    "    print(f\"‚úì Level column: '{level_col}' ‚Üí {df['level'].unique()}\")\n",
    "\n",
    "# =================================================================\n",
    "# SELECT NUMERICAL FEATURES\n",
    "# =================================================================\n",
    "print(f\"\\n[3/8] Selecting numerical features...\")\n",
    "\n",
    "# Exclude non-feature columns\n",
    "exclude = [school_col, level_col, 'school', 'level', 'School ID', 'Name of School',\n",
    "           'Latitude', 'Longitude', 'X_COORDINATE', 'Y_COORDINATE',\n",
    "           'Street Address', 'City', 'State', 'ZIP Code', 'Phone Number',\n",
    "           'RCDTS Code', 'Ward', 'Police District', 'Community Area Number',\n",
    "           'College Enrollment (number of students)', 'Location', 'Link']\n",
    "\n",
    "# Get numerical columns\n",
    "num_cols = []\n",
    "for col in df.columns:\n",
    "    if col in exclude:\n",
    "        continue\n",
    "    # Try to convert to numeric\n",
    "    try:\n",
    "        test = pd.to_numeric(df[col], errors='coerce')\n",
    "        if test.notna().sum() > len(df) * 0.5:  # At least 50% non-null\n",
    "            num_cols.append(col)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "print(f\"‚úì Found {len(num_cols)} numerical features\")\n",
    "\n",
    "# Convert to numeric and clean\n",
    "for col in num_cols:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "# =================================================================\n",
    "# CREATE EMBEDDINGS DATAFRAME\n",
    "# =================================================================\n",
    "print(f\"\\n[4/8] Creating embeddings...\")\n",
    "\n",
    "embeddings = pd.DataFrame()\n",
    "embeddings['school'] = df['school']\n",
    "\n",
    "# Add numerical features\n",
    "for col in num_cols:\n",
    "    embeddings[col] = df[col].fillna(df[col].median())\n",
    "\n",
    "# One-hot encode level\n",
    "if 'level' in df.columns:\n",
    "    for lvl in ['ES', 'MS', 'HS']:\n",
    "        embeddings[f'level_{lvl}'] = (df['level'] == lvl).astype(int)\n",
    "\n",
    "# Create aggregated features\n",
    "feature_map = {\n",
    "    'safety': ['Safety Score', 'safety'],\n",
    "    'attendance': ['Average Student Attendance', 'attendance'],\n",
    "    'misconduct': ['Rate of Misconducts (per 100 students)', 'Rate of Misconducts (per 100 students) ', 'misconduct'],\n",
    "    'instr': ['Instruction Score', 'instr'],\n",
    "    'teachers': ['Teachers Score', 'teachers'],\n",
    "    'leaders': ['Leaders Score', 'leaders']\n",
    "}\n",
    "\n",
    "found_features = {}\n",
    "for short_name, possible_names in feature_map.items():\n",
    "    for full_name in possible_names:\n",
    "        if full_name in df.columns:\n",
    "            found_features[short_name] = full_name\n",
    "            break\n",
    "\n",
    "# Behavioral composite\n",
    "if 'safety' in found_features and 'misconduct' in found_features:\n",
    "    vals = (df[found_features['safety']].fillna(df[found_features['safety']].median()) -\n",
    "            df[found_features['misconduct']].fillna(df[found_features['misconduct']].median()) * 10)\n",
    "    embeddings['behavioral_composite'] = vals.fillna(0)\n",
    "\n",
    "print(f\"‚úì Embedding shape: {embeddings.shape}\")\n",
    "\n",
    "# =================================================================\n",
    "# NORMALIZE AND SCALE\n",
    "# =================================================================\n",
    "print(f\"\\n[5/8] Normalizing embeddings...\")\n",
    "\n",
    "# Separate ID and features\n",
    "school_ids = embeddings['school'].values\n",
    "X = embeddings.drop(columns=['school']).values\n",
    "\n",
    "# Fill any remaining NaN with 0\n",
    "X = np.nan_to_num(X, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "# Standardize\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "print(f\"‚úì Standardized to mean=0, std=1\")\n",
    "print(f\"  Shape: {X_scaled.shape}\")\n",
    "\n",
    "# Save full embeddings (TASK 1.1 OUTPUT)\n",
    "emb_full = pd.DataFrame(X_scaled, columns=[f'feat_{i}' for i in range(X_scaled.shape[1])])\n",
    "emb_full.insert(0, 'school', school_ids)\n",
    "if 'level' in df.columns:\n",
    "    emb_full.insert(1, 'level', df['level'].values)\n",
    "\n",
    "# Add original features\n",
    "for short_name, full_name in found_features.items():\n",
    "    emb_full[short_name] = df[full_name].fillna(df[full_name].median()).values\n",
    "\n",
    "emb_full_path = PROC / \"embeddings_cps.csv\"\n",
    "emb_full.to_csv(emb_full_path, index=False)\n",
    "print(f\"\\n‚úì TASK 1.1 OUTPUT: {emb_full_path.name}\")\n",
    "print(f\"  Rows: {len(emb_full)}, Columns: {len(emb_full.columns)}\")\n",
    "\n",
    "# =================================================================\n",
    "# TASK 1.2: PCA PROJECTION TO 2D\n",
    "# =================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TASK 1.2: PROJECTING TO 2D WITH PCA\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\n[6/8] Applying PCA...\")\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "print(f\"‚úì PCA complete\")\n",
    "print(f\"  PC1 variance: {pca.explained_variance_ratio_[0]*100:.2f}%\")\n",
    "print(f\"  PC2 variance: {pca.explained_variance_ratio_[1]*100:.2f}%\")\n",
    "print(f\"  Total: {pca.explained_variance_ratio_.sum()*100:.2f}%\")\n",
    "\n",
    "# Create 2D embeddings dataframe\n",
    "emb_2d = pd.DataFrame({\n",
    "    'school': school_ids,\n",
    "    'x': X_pca[:, 0],\n",
    "    'y': X_pca[:, 1]\n",
    "})\n",
    "\n",
    "if 'level' in df.columns:\n",
    "    emb_2d['level'] = df['level'].values\n",
    "\n",
    "# Add original features with SHORT names for dashboard\n",
    "for short_name, full_name in found_features.items():\n",
    "    emb_2d[short_name] = df[full_name].fillna(df[full_name].median()).values\n",
    "\n",
    "# Save 2D embeddings (TASK 1.2 OUTPUT)\n",
    "emb_2d_path = PROC / \"embeddings_cps_2d.csv\"\n",
    "emb_2d.to_csv(emb_2d_path, index=False)\n",
    "print(f\"\\n‚úì TASK 1.2 OUTPUT: {emb_2d_path.name}\")\n",
    "print(f\"  Rows: {len(emb_2d)}, Columns: {len(emb_2d.columns)}\")\n",
    "\n",
    "# =================================================================\n",
    "# ENHANCEMENT: ADD OUTLIER SCORES, CLUSTERS, ETC.\n",
    "# =================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ENHANCEMENTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\n[7/8] Adding outlier scores...\")\n",
    "\n",
    "# Use available features for outlier detection\n",
    "outlier_features = [c for c in ['safety', 'misconduct', 'instr'] if c in emb_2d.columns]\n",
    "if len(outlier_features) == 0:\n",
    "    outlier_features = ['x', 'y']\n",
    "\n",
    "X_outlier = emb_2d[outlier_features].fillna(0).values\n",
    "X_outlier_scaled = StandardScaler().fit_transform(X_outlier)\n",
    "\n",
    "nbrs = NearestNeighbors(n_neighbors=min(11, len(emb_2d)))\n",
    "nbrs.fit(X_outlier_scaled)\n",
    "distances, _ = nbrs.kneighbors(X_outlier_scaled)\n",
    "\n",
    "outlier_scores = distances[:, 1:].mean(axis=1)\n",
    "outlier_min, outlier_max = outlier_scores.min(), outlier_scores.max()\n",
    "if outlier_max > outlier_min:\n",
    "    emb_2d['outlier_score'] = ((outlier_scores - outlier_min) / (outlier_max - outlier_min) * 100)\n",
    "else:\n",
    "    emb_2d['outlier_score'] = 50.0\n",
    "\n",
    "print(f\"‚úì Outlier scores calculated\")\n",
    "\n",
    "# Clusters\n",
    "print(f\"Adding cluster labels...\")\n",
    "try:\n",
    "    emb_2d['cluster_x'] = pd.qcut(emb_2d['x'], q=3, labels=['Low', 'Mid', 'High'], duplicates='drop')\n",
    "    emb_2d['cluster_y'] = pd.qcut(emb_2d['y'], q=3, labels=['Low', 'Mid', 'High'], duplicates='drop')\n",
    "    emb_2d['cluster'] = emb_2d['cluster_x'].astype(str) + '-' + emb_2d['cluster_y'].astype(str)\n",
    "    print(f\"‚úì Created {emb_2d['cluster'].nunique()} clusters\")\n",
    "except:\n",
    "    emb_2d['cluster'] = 'Unknown'\n",
    "\n",
    "# Behavior score\n",
    "print(f\"Calculating behavior score...\")\n",
    "if 'safety' in emb_2d.columns and 'misconduct' in emb_2d.columns:\n",
    "    behavior = emb_2d['safety'] - emb_2d['misconduct'] * 10\n",
    "    if 'attendance' in emb_2d.columns:\n",
    "        behavior = behavior + emb_2d['attendance']\n",
    "\n",
    "    b_min, b_max = behavior.min(), behavior.max()\n",
    "    if b_max > b_min:\n",
    "        emb_2d['behavior_score'] = ((behavior - b_min) / (b_max - b_min) * 100)\n",
    "    else:\n",
    "        emb_2d['behavior_score'] = 50.0\n",
    "    print(f\"‚úì Behavior score: {emb_2d['behavior_score'].min():.1f} to {emb_2d['behavior_score'].max():.1f}\")\n",
    "else:\n",
    "    emb_2d['behavior_score'] = 50.0\n",
    "\n",
    "# Academic score\n",
    "if 'instr' in emb_2d.columns:\n",
    "    emb_2d['academic_score'] = emb_2d['instr'].fillna(emb_2d['instr'].median())\n",
    "    print(f\"‚úì Academic score added\")\n",
    "else:\n",
    "    emb_2d['academic_score'] = 50.0\n",
    "\n",
    "# Deviations by level\n",
    "if 'level' in emb_2d.columns:\n",
    "    for col in ['safety', 'instr', 'misconduct']:\n",
    "        if col in emb_2d.columns:\n",
    "            emb_2d[f'{col}_dev'] = emb_2d[col] - emb_2d.groupby('level')[col].transform('mean')\n",
    "\n",
    "# Save enhanced 2D embeddings\n",
    "emb_2d_enh_path = PROC / \"embeddings_cps_2d_enhanced.csv\"\n",
    "emb_2d.to_csv(emb_2d_enh_path, index=False)\n",
    "print(f\"\\n‚úì ENHANCED OUTPUT: {emb_2d_enh_path.name}\")\n",
    "print(f\"  Rows: {len(emb_2d)}, Columns: {len(emb_2d.columns)}\")\n",
    "\n",
    "# =================================================================\n",
    "# SPATIAL DATA ENRICHMENT\n",
    "# =================================================================\n",
    "print(f\"\\n[8/8] Processing spatial data...\")\n",
    "\n",
    "spatial_path = PROC / \"cps_spatial.csv\"\n",
    "if spatial_path.exists():\n",
    "    spatial = pd.read_csv(spatial_path)\n",
    "\n",
    "    # Ensure school IDs match types\n",
    "    spatial['school'] = spatial['school'].astype(str)\n",
    "\n",
    "    # Merge\n",
    "    merge_cols = ['school', 'cluster', 'outlier_score', 'behavior_score', 'academic_score']\n",
    "    merge_cols = [c for c in merge_cols if c in emb_2d.columns]\n",
    "\n",
    "    spatial_enh = spatial.merge(emb_2d[merge_cols], on='school', how='left')\n",
    "\n",
    "    spatial_enh_path = PROC / \"cps_spatial_enhanced.csv\"\n",
    "    spatial_enh.to_csv(spatial_enh_path, index=False)\n",
    "    print(f\"‚úì SPATIAL OUTPUT: {spatial_enh_path.name}\")\n",
    "    print(f\"  Rows: {len(spatial_enh)}, Columns: {len(spatial_enh.columns)}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No spatial file found, skipping\")\n",
    "\n",
    "# =================================================================\n",
    "# SUMMARY\n",
    "# =================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COMPLETE!\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nüìÅ Output files in: {PROC.absolute()}\")\n",
    "print(f\"\\n‚úÖ TASK 1.1: embeddings_cps.csv\")\n",
    "print(f\"   - High-dimensional embeddings with {X_scaled.shape[1]} features\")\n",
    "print(f\"\\n‚úÖ TASK 1.2: embeddings_cps_2d.csv\")\n",
    "print(f\"   - 2D PCA projection (x, y coordinates)\")\n",
    "print(f\"   - Method: PCA\")\n",
    "print(f\"   - Variance explained: {pca.explained_variance_ratio_.sum()*100:.2f}%\")\n",
    "print(f\"\\n‚úÖ ENHANCED: embeddings_cps_2d_enhanced.csv\")\n",
    "print(f\"   - All 2D data plus outlier_score, cluster, behavior_score, etc.\")\n",
    "\n",
    "if 'level' in emb_2d.columns:\n",
    "    print(f\"\\nüìä Summary by level:\")\n",
    "    summary_cols = [c for c in ['safety', 'misconduct', 'instr', 'behavior_score'] if c in emb_2d.columns]\n",
    "    if summary_cols:\n",
    "        print(emb_2d.groupby('level')[summary_cols].mean().round(1))\n",
    "\n",
    "print(f\"\\nüéØ Next: Copy enhanced files to web/data/ folder\")\n",
    "print(f\"   cp {emb_2d_enh_path} web/data/\")\n",
    "if spatial_path.exists():\n",
    "    print(f\"   cp {spatial_enh_path} web/data/\")\n",
    "\n",
    "print(\"\\n‚úÖ Pipeline complete!\")"
   ],
   "id": "b44e88c560991942",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "COMPLETE EMBEDDING PIPELINE - TASK 1.1 & 1.2\n",
      "======================================================================\n",
      "\n",
      "[1/8] Loading raw data...\n",
      "‚úì Loaded: CPS_Data.csv\n",
      "  Rows: 566, Columns: 79\n",
      "\n",
      "======================================================================\n",
      "TASK 1.1: CONSTRUCTING EMBEDDINGS\n",
      "======================================================================\n",
      "\n",
      "[2/8] School identifier: 'School ID' ‚Üí 'school'\n",
      "‚úì Level column: 'Elementary, Middle, or High School' ‚Üí ['ES' 'HS' 'MS']\n",
      "\n",
      "[3/8] Selecting numerical features...\n",
      "‚úì Found 30 numerical features\n",
      "\n",
      "[4/8] Creating embeddings...\n",
      "‚úì Embedding shape: (566, 35)\n",
      "\n",
      "[5/8] Normalizing embeddings...\n",
      "‚úì Standardized to mean=0, std=1\n",
      "  Shape: (566, 34)\n",
      "\n",
      "‚úì TASK 1.1 OUTPUT: embeddings_cps.csv\n",
      "  Rows: 566, Columns: 41\n",
      "\n",
      "======================================================================\n",
      "TASK 1.2: PROJECTING TO 2D WITH PCA\n",
      "======================================================================\n",
      "\n",
      "[6/8] Applying PCA...\n",
      "‚úì PCA complete\n",
      "  PC1 variance: 29.18%\n",
      "  PC2 variance: 8.34%\n",
      "  Total: 37.52%\n",
      "\n",
      "‚úì TASK 1.2 OUTPUT: embeddings_cps_2d.csv\n",
      "  Rows: 566, Columns: 9\n",
      "\n",
      "======================================================================\n",
      "ENHANCEMENTS\n",
      "======================================================================\n",
      "\n",
      "[7/8] Adding outlier scores...\n",
      "‚úì Outlier scores calculated\n",
      "Adding cluster labels...\n",
      "‚úì Created 9 clusters\n",
      "Calculating behavior score...\n",
      "‚úì Behavior score: 0.0 to 100.0\n",
      "‚úì Academic score added\n",
      "\n",
      "‚úì ENHANCED OUTPUT: embeddings_cps_2d_enhanced.csv\n",
      "  Rows: 566, Columns: 18\n",
      "\n",
      "[8/8] Processing spatial data...\n",
      "‚úì SPATIAL OUTPUT: cps_spatial_enhanced.csv\n",
      "  Rows: 566, Columns: 11\n",
      "\n",
      "======================================================================\n",
      "COMPLETE!\n",
      "======================================================================\n",
      "\n",
      "üìÅ Output files in: /Users/garimagoel/PycharmProjects/JupyterProject6/data/processed\n",
      "\n",
      "‚úÖ TASK 1.1: embeddings_cps.csv\n",
      "   - High-dimensional embeddings with 34 features\n",
      "\n",
      "‚úÖ TASK 1.2: embeddings_cps_2d.csv\n",
      "   - 2D PCA projection (x, y coordinates)\n",
      "   - Method: PCA\n",
      "   - Variance explained: 37.52%\n",
      "\n",
      "‚úÖ ENHANCED: embeddings_cps_2d_enhanced.csv\n",
      "   - All 2D data plus outlier_score, cluster, behavior_score, etc.\n",
      "\n",
      "üìä Summary by level:\n",
      "       safety  misconduct  instr  behavior_score\n",
      "level                                           \n",
      "ES       49.4        22.5   49.2            89.3\n",
      "HS       49.5        15.6   44.5            91.6\n",
      "MS       48.0         7.5   36.9            95.1\n",
      "\n",
      "üéØ Next: Copy enhanced files to web/data/ folder\n",
      "   cp data/processed/embeddings_cps_2d_enhanced.csv web/data/\n",
      "   cp data/processed/cps_spatial_enhanced.csv web/data/\n",
      "\n",
      "‚úÖ Pipeline complete!\n"
     ]
    }
   ],
   "execution_count": 22
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
